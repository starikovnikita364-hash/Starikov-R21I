from random import uniform
import matplotlib.pyplot as plt
import numpy as np

def mse(outputs, targets):
    """Среднеквадратичная ошибка"""
    return np.mean((np.array(outputs) - np.array(targets)) ** 2)

def r_squared(outputs, targets):
    """Коэффициент детерминации R²"""
    outputs = np.array(outputs)
    targets = np.array(targets)
    ss_res = np.sum((targets - outputs) ** 2)
    ss_tot = np.sum((targets - np.mean(targets)) ** 2)
    return 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

class LinearRegression:
    def __init__(self, features_num, learning_rate=0.0000001):
        # Инициализация весов нулями для воспроизводимости
        self.weights = np.zeros(features_num + 1)  # +1 для bias
        self.features_num = features_num
        self.learning_rate = learning_rate
        
    def forward(self, input_features):
        """Прямой проход: вычисление прогноза"""
        # input_features: [x1, x2, ..., xn]
        # weights: [w1, w2, ..., wn, bias]
        output = self.weights[-1]  # bias
        for i in range(self.features_num):
            output += self.weights[i] * input_features[i]
        return output
    
    def fit_vectorized(self, inputs, targets, epochs=10000, verbose=True):
        """Векторизованное обучение модели (более эффективное)"""
        inputs = np.array(inputs)
        targets = np.array(targets)
        n_samples = len(targets)
        
        errors = []
        r_squared_values = []
        
        # Добавляем столбец из единиц для bias
        X = np.column_stack((inputs, np.ones(n_samples)))
        
        for epoch in range(epochs):
            # Прямой проход
            predictions = X.dot(self.weights)
            
            # Вычисление ошибки
            error = predictions - targets
            
            # Градиенты
            gradients = (2/n_samples) * X.T.dot(error)
            
            # Обновление весов
            self.weights -= self.learning_rate * gradients
            
            # Вычисление метрик
            mse_value = np.mean(error ** 2)
            r2 = 1 - np.sum(error ** 2) / np.sum((targets - np.mean(targets)) ** 2)
            
            errors.append(mse_value)
            r_squared_values.append(r2)
            
            if verbose and (epoch % 1000 == 0 or epoch == epochs - 1):
                print(f"Эпоха: {epoch:4d}, MSE: {mse_value:.6f}, R²: {r2:.4f}")
        
        return errors, r_squared_values
    
    def fit(self, inputs, targets, epochs=10000, verbose=True):
        """Обучение модели (невекторизованная версия для понимания)"""
        errors = []
        r_squared_values = []
        n_samples = len(targets)
        
        for epoch in range(epochs):
            total_error = 0
            predictions = []
            
            # Проход по всем данным
            for i in range(n_samples):
                # Прямой проход
                pred = self.forward(inputs[i])
                predictions.append(pred)
                
                # Ошибка
                error = pred - targets[i]
                total_error += error ** 2
                
                # Обновление градиентов
                # Для bias
                self.weights[-1] -= self.learning_rate * (2/n_samples) * error
                
                # Для остальных весов
                for j in range(self.features_num):
                    self.weights[j] -= self.learning_rate * (2/n_samples) * error * inputs[i][j]
            
            # Вычисление метрик
            mse_value = total_error / n_samples
            r2 = r_squared(predictions, targets)
            
            errors.append(mse_value)
            r_squared_values.append(r2)
            
            if verbose and (epoch % 1000 == 0 or epoch == epochs - 1):
                print(f"Эпоха: {epoch:4d}, MSE: {mse_value:.6f}, R²: {r2:.4f}")
        
        return errors, r_squared_values
    
    def predict(self, inputs):
        """Прогнозирование для новых данных"""
        predictions = []
        for inp in inputs:
            predictions.append(self.forward(inp))
        return predictions
    
    def get_equation(self):
        """Получение уравнения регрессии"""
        equation = f"Y = {self.weights[-1]:.6f}"
        for i in range(self.features_num):
            sign = "+" if self.weights[i] >= 0 else ""
            equation += f" {sign}{self.weights[i]:.8f}*X{i+1}"
        return equation
    
    def get_coefficients(self):
        """Возвращает коэффициенты"""
        return {
            'intercept': self.weights[-1],
            'coef_X1': self.weights[0],
            'coef_X4': self.weights[1] if self.features_num > 1 else None
        }

def analytical_solution(X1, X4, Y):
    """Аналитическое решение (метод наименьших квадратов)"""
    # Преобразуем в numpy массивы
    X1_arr = np.array(X1)
    X4_arr = np.array(X4)
    Y_arr = np.array(Y)
    n = len(Y)
    
    # Создаем матрицу признаков с колонкой для intercept
    X = np.column_stack((np.ones(n), X1_arr, X4_arr))
    
    # Решаем нормальные уравнения: (X^T * X) * β = X^T * y
    XT_X = X.T.dot(X)
    XT_y = X.T.dot(Y_arr)
    
    # Проверяем, что матрица обратима
    if np.linalg.det(XT_X) == 0:
        print("Матрица X^T*X вырождена, используем псевдообратную")
        beta = np.linalg.pinv(XT_X).dot(XT_y)
    else:
        beta = np.linalg.inv(XT_X).dot(XT_y)
    
    return beta

def main():
    # Данные
    data = [
        [56, 58000, 36],
        [23, 20000, 33],
        [13, 15000, 31],
        [54, 51000, 44],
        [21, 16000, 75],
        [89, 94000, 69],
        [27, 31000, 32],
        [36, 32000, 43],
        [91, 88000, 67],
        [55, 64000, 87],
        [72, 69000, 77],
        [33, 38000, 65],
        [50, 40000, 54],
        [13, 15000, 39],
        [75, 82000, 57],
        [11, 13000, 48],
        [18, 25000, 98],
        [49, 54000, 87],
        [61, 62000, 78],
        [44, 53000, 63],
        [17, 21000, 51],
        [20, 24000, 59],
        [87, 33500, 125],
        [75, 25000, 122]
    ]
    
    # Разделение данных
    Y = [row[0] for row in data]
    X1 = [row[1] for row in data]
    X4 = [row[2] for row in data]
    
    print("="*80)
    print("АНАЛИТИЧЕСКОЕ РЕШЕНИЕ (МЕТОД НАИМЕНЬШИХ КВАДРАТОВ)")
    print("="*80)
    
    # Получаем аналитическое решение
    beta = analytical_solution(X1, X4, Y)
    
    print(f"Коэффициенты из аналитического решения:")
    print(f"Intercept (b0): {beta[0]:.8f}")
    print(f"Коэффициент для X1 (b1): {beta[1]:.8f}")
    print(f"Коэффициент для X4 (b2): {beta[2]:.8f}")
    print()
    print(f"Уравнение: Y = {beta[0]:.8f} + {beta[1]:.8f}*X1 + {beta[2]:.8f}*X4")
    print(f"Уравнение (округленно): Y = {beta[0]:.2f} + {beta[1]:.6f}*X1 + {beta[2]:.4f}*X4")
    
    # Прогнозы на основе аналитического решения
    X_matrix = np.column_stack((np.ones(len(Y)), X1, X4))
    predictions_analytical = X_matrix.dot(beta)
    
    # Оценка качества
    mse_analytical = mse(predictions_analytical, Y)
    r2_analytical = r_squared(predictions_analytical, Y)
    
    print(f"\nКачество аналитического решения:")
    print(f"MSE: {mse_analytical:.4f}")
    print(f"RMSE: {np.sqrt(mse_analytical):.4f}")
    print(f"R²: {r2_analytical:.4f}")
    
    print("\n" + "="*80)
    print("ГРАДИЕНТНЫЙ СПУСК (для сравнения)")
    print("="*80)
    
    # Подготовка данных для градиентного спуска
    inputs = [[x1, x4] for x1, x4 in zip(X1, X4)]
    
    # Создаем модель с большей скоростью обучения
    model = LinearRegression(features_num=2, learning_rate=0.0000003)
    
    # Используем аналитическое решение как начальное приближение
    model.weights[0] = beta[1]  # Коэффициент для X1
    model.weights[1] = beta[2]  # Коэффициент для X4
    model.weights[2] = beta[0]  # Intercept
    
    print("Начальные веса (из аналитического решения):")
    print(model.get_equation())
    
    # Обучение (немного дообучим)
    errors, r2_values = model.fit(
        inputs, 
        Y, 
        epochs=2000,
        verbose=True
    )
    
    print("\n" + "="*80)
    print("СРАВНЕНИЕ РЕЗУЛЬТАТОВ")
    print("="*80)
    print("Из Excel (ваш результат):")
    print("Y = -14.23851937 + 0.000806598*X1 + 0.393617821*X4")
    print()
    print("Аналитическое решение (метод наименьших квадратов):")
    print(f"Y = {beta[0]:.8f} + {beta[1]:.8f}*X1 + {beta[2]:.8f}*X4")
    print()
    print("Градиентный спуск:")
    print(model.get_equation())
    
    # Проверка расхождений
    print("\n" + "="*80)
    print("АНАЛИЗ РАСХОЖДЕНИЙ")
    print("="*80)
    
    # Ваши коэффициенты из Excel
    excel_coef = {
        'intercept': -14.23851937,
        'X1': 0.000806598,
        'X4': 0.393617821
    }
    
    # Различия
    diff_intercept = abs(beta[0] - excel_coef['intercept'])
    diff_X1 = abs(beta[1] - excel_coef['X1'])
    diff_X4 = abs(beta[2] - excel_coef['X4'])
    
    print(f"Разница в intercept: {diff_intercept:.8f}")
    print(f"Разница в коэффициенте X1: {diff_X1:.8f}")
    print(f"Разница в коэффициенте X4: {diff_X4:.8f}")
    
    # Возможные причины
    print("\nВозможные причины расхождений:")
    print("1. Разный метод расчета (Excel использует собственную реализацию)")
    print("2. Округление в Excel")
    print("3. Обработка выбросов")
    print("4. Численная стабильность вычислений")
    
    # Проверка на одинаковых данных
    print("\n" + "="*80)
    print("ПРОВЕРКА НА ИСКЛЮЧЕНИИ ПОСЛЕДНИХ ДВУХ СТРОК")
    print("="*80)
    
    # Проверим без последних двух строк (которые выглядят как выбросы)
    data_clean = data[:-2]
    
    Y_clean = [row[0] for row in data_clean]
    X1_clean = [row[1] for row in data_clean]
    X4_clean = [row[2] for row in data_clean]
    
    beta_clean = analytical_solution(X1_clean, X4_clean, Y_clean)
    
    print(f"На чистых данных ({len(data_clean)} наблюдений):")
    print(f"Intercept: {beta_clean[0]:.8f}")
    print(f"Коэффициент X1: {beta_clean[1]:.8f}")
    print(f"Коэффициент X4: {beta_clean[2]:.8f}")
    print(f"Уравнение: Y = {beta_clean[0]:.2f} + {beta_clean[1]:.6f}*X1 + {beta_clean[2]:.4f}*X4")
    
    # Визуализация
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # 1. Фактические vs предсказанные (аналитическое)
    axes[0, 0].scatter(Y, predictions_analytical, alpha=0.7)
    axes[0, 0].plot([min(Y), max(Y)], [min(Y), max(Y)], 'r--')
    axes[0, 0].set_xlabel('Фактические Y')
    axes[0, 0].set_ylabel('Предсказанные Y (аналитическое)')
    axes[0, 0].set_title('Аналитическое решение')
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. Зависимость Y от X1
    axes[0, 1].scatter(X1, Y, alpha=0.7)
    axes[0, 1].set_xlabel('X1')
    axes[0, 1].set_ylabel('Y')
    axes[0, 1].set_title('Зависимость Y от X1')
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. Зависимость Y от X4
    axes[0, 2].scatter(X4, Y, alpha=0.7)
    axes[0, 2].set_xlabel('X4')
    axes[0, 2].set_ylabel('Y')
    axes[0, 2].set_title('Зависимость Y от X4')
    axes[0, 2].grid(True, alpha=0.3)
    
    # 4. Ошибки градиентного спуска
    axes[1, 0].plot(errors, 'b-', linewidth=2)
    axes[1, 0].set_xlabel('Эпоха')
    axes[1, 0].set_ylabel('MSE')
    axes[1, 0].set_title('Сходимость градиентного спуска')
    axes[1, 0].grid(True, alpha=0.3)
    
    # 5. R² градиентного спуска
    axes[1, 1].plot(r2_values, 'g-', linewidth=2)
    axes[1, 1].set_xlabel('Эпоха')
    axes[1, 1].set_ylabel('R²')
    axes[1, 1].set_title('Изменение R²')
    axes[1, 1].grid(True, alpha=0.3)
    
    # 6. Сравнение коэффициентов
    labels = ['Intercept', 'X1', 'X4']
    excel_vals = [excel_coef['intercept'], excel_coef['X1'], excel_coef['X4']]
    analytical_vals = [beta[0], beta[1], beta[2]]
    
    x = np.arange(len(labels))
    width = 0.35
    
    axes[1, 2].bar(x - width/2, excel_vals, width, label='Excel', alpha=0.8)
    axes[1, 2].bar(x + width/2, analytical_vals, width, label='Аналитическое', alpha=0.8)
    axes[1, 2].set_xlabel('Коэффициенты')
    axes[1, 2].set_ylabel('Значение')
    axes[1, 2].set_title('Сравнение коэффициентов')
    axes[1, 2].set_xticks(x)
    axes[1, 2].set_xticklabels(labels)
    axes[1, 2].legend()
    axes[1, 2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Детальный анализ последних двух наблюдений
    print("\n" + "="*80)
    print("АНАЛИЗ ПОСЛЕДНИХ ДВУХ НАБЛЮДЕНИЙ")
    print("="*80)
    print("Индекс | Y  | X1    | X4  | Особенность")
    print("-" * 55)
    
    for i in range(len(data)-2, len(data)):
        y, x1, x4 = data[i]
        print(f"{i:6d} | {y:2.0f} | {x1:5.0f} | {x4:3.0f} | ", end="")
        
        # Проверяем на выбросы
        is_outlier_x1 = x1 < np.mean(X1) - 2*np.std(X1) or x1 > np.mean(X1) + 2*np.std(X1)
        is_outlier_x4 = x4 < np.mean(X4) - 2*np.std(X4) or x4 > np.mean(X4) + 2*np.std(X4)
        
        if is_outlier_x1 and is_outlier_x4:
            print("Выброс по X1 и X4")
        elif is_outlier_x1:
            print("Выброс по X1")
        elif is_outlier_x4:
            print("Выброс по X4")
        else:
            print("Нормальное наблюдение")

if __name__ == '__main__':
    main()
